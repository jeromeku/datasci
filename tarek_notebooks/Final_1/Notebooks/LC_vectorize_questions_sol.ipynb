{
 "metadata": {
  "name": "",
  "signature": "sha256:00d6dbce55be2a9b9ff05b64c110ec448580dedb03152fb73ee100a05abbca81"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Import Necessary Packages and Modules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load Live Community Questions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "posts_table = pd.read_csv('../data/ml_posts_1.csv')\n",
      "tags = posts_table[['cached_question_tag_list']]\n",
      "tags = np.array(tags).ravel()\n",
      "unique_tags = set(tags)\n",
      "\n",
      "tag_labels_dict={}\n",
      "tag_names=[]\n",
      "\n",
      "for tag_id, some_tag in enumerate(unique_tags):\n",
      "    tag_labels_dict[some_tag]=tag_id\n",
      "    tag_names.append(some_tag)\n",
      "\n",
      "tag_labels = [tag_labels_dict[post_label] for post_label in tags]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Get Some Question Subjects"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "post_subjects = posts_table[['subject']][:4]\n",
      "subjects = np.array(post_subjects).ravel().tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Tokenize the Questions using Unigrams"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Q1. Create a (term, Frequency) tuple for each question?  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subjects"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "['Anyone receive an acceptep from IRS 2011 tax year?',\n",
        " 'Can everyone please post Time and Date- Filed, Accepted/Rejected, Date of Pay, ANY States POST Which States Please!',\n",
        " 'has anyone else received letter 4883c from irs?? if so how long did if take to get your money afterward??',\n",
        " 'Claim as dependant']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subjects_tokenized = [ subject.split() for subject in subjects]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_freq = [Counter(tokens).items() for tokens in subjects_tokenized]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Q2. Generate a Global mapping between each unique word mentioned in the questions and some unique integer. For example: feature_names_maping = {u'2011': 0,\n",
      " u'4883c': 1,\n",
      "...\n",
      " u'any': 7}."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_terms = set()\n",
      "for subject_tokens in subjects_tokenized:\n",
      "    unique_terms.update(set(subject_tokens))\n",
      "\n",
      "feature_names = list(unique_terms)\n",
      "feature_names_maping = dict( [(feat, ind) for ind, feat in enumerate(feature_names)] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Q3. For each question subject, apply the mapping to the corresponding (term, freq) to get (term_id, freq). For example, for the first question we would \n",
      "[1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "termid_freq = []\n",
      "for subject_term_freq in term_freq:\n",
      "    subject_termid_freq =[(feature_names_maping[term],freq) for term, freq in subject_term_freq]\n",
      "    termid_freq.append(subject_termid_freq)\n",
      "termid_freq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[[(27, 1),\n",
        "  (14, 1),\n",
        "  (40, 1),\n",
        "  (30, 1),\n",
        "  (4, 1),\n",
        "  (31, 1),\n",
        "  (6, 1),\n",
        "  (5, 1),\n",
        "  (38, 1)],\n",
        " [(0, 1),\n",
        "  (1, 1),\n",
        "  (9, 1),\n",
        "  (36, 1),\n",
        "  (25, 1),\n",
        "  (41, 1),\n",
        "  (16, 1),\n",
        "  (17, 1),\n",
        "  (43, 2),\n",
        "  (32, 1),\n",
        "  (33, 1),\n",
        "  (22, 1),\n",
        "  (35, 1),\n",
        "  (23, 1),\n",
        "  (12, 1),\n",
        "  (11, 1),\n",
        "  (46, 1)],\n",
        " [(18, 1),\n",
        "  (39, 1),\n",
        "  (14, 1),\n",
        "  (26, 1),\n",
        "  (20, 1),\n",
        "  (44, 1),\n",
        "  (3, 1),\n",
        "  (2, 1),\n",
        "  (8, 1),\n",
        "  (37, 1),\n",
        "  (19, 1),\n",
        "  (15, 1),\n",
        "  (45, 1),\n",
        "  (21, 1),\n",
        "  (34, 1),\n",
        "  (28, 1),\n",
        "  (24, 1),\n",
        "  (10, 1),\n",
        "  (13, 2)],\n",
        " [(42, 1), (7, 1), (29, 1)]]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "How to tokenize using 'sklearn'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = CountVectorizer(  ngram_range=(1, 1))\n",
      "X= vectorizer.fit_transform(subjects)\n",
      "feature_names = vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_question = ['has anyone else received letter 4883c from irs?? if so how long did if take to get your money afterward??']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test_question = vectorizer.transform(test_question)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}